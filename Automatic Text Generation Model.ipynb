{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3d5a83",
   "metadata": {},
   "source": [
    "### Importing Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb1ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import string\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce20cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67c33d",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420645d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_link.text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9848d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  From fairest creatures we desire increase,'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3b64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cut off the preface, foreword, copyright instructions from the file.\n",
    "df = data[253:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a97f907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad94a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we make the data set 'df' continous\n",
    "df = ' '.join(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31af53",
   "metadata": {},
   "source": [
    "* The below function will remove the punctuations, keep only the alpha-numeric characters and convert all alphabets into lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa828389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text(doc):\n",
    "    tokens = doc.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94913e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477e05b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c932a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27956"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e150bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 50 + 1\n",
    "lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b725acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(length, len(tokens)):\n",
    "    seq = tokens[i - length:i]\n",
    "    line = ' '.join(seq)\n",
    "    lines.append(line)\n",
    "    if i > 250000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc52dbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from fairest creatures we desire increase that thereby beautys rose might never die but as the riper should by time decease his tender heir might bear his memory but thou contracted to thine own bright eyes feedst thy lights flame with selfsubstantial fuel making a famine where abundance lies thy self'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c5a012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'creatures we desire increase that thereby beautys rose might never die but as the riper should by time decease his tender heir might bear his memory but thou contracted to thine own bright eyes feedst thy lights flame with selfsubstantial fuel making a famine where abundance lies thy self thy foe'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1045883",
   "metadata": {},
   "source": [
    "## Working of model:\n",
    "* Firstly we have successfully converted the given data into lines with 51 words each.\n",
    "* What will do next is that, we split the data set 'lines' into x, y. x contains the first 50 words of each element of 'lines' data set, the y variable contains the 51st word of each element in 'lines'.\n",
    "* Note that x will be a 2D array, while y will be a 1D array.\n",
    "* Before split data into x, y we will tokenize the data, i.e. each distinct word will be assigned a distinct real number.\n",
    "* We then split the x, y variables into train and test sets and then build the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2a9a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "word_seq = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78369bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_seq = np.array(word_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aedc0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = word_seq[:, : -1], word_seq[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82ef8c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249951"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9de12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:200000, :]\n",
    "y_train = y[:200000]\n",
    "x_test = x[200000:, :]\n",
    "y_test = y[200000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4f32b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 49951)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94454e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0219a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = vocab)\n",
    "y_test = to_categorical(y_test, num_classes = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f77e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d46d33",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65a256ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(vocab, 50, input_length = seq_len))\n",
    "model_rnn.add(LSTM(256, return_sequences = True))\n",
    "model_rnn.add(LSTM(256))\n",
    "model_rnn.add(Dense(256, activation = 'relu'))\n",
    "model_rnn.add(Dense(vocab, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "712615c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 249951, 50)        743700    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 249951, 256)       314368    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14874)             3822618   \n",
      "=================================================================\n",
      "Total params: 5,471,790\n",
      "Trainable params: 5,471,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e021df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f77ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 249951) for input KerasTensor(type_spec=TensorSpec(shape=(None, 249951), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (2000, 50).\n",
      "100/100 [==============================] - 650s 6s/step - loss: 6.7529 - accuracy: 0.0295\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 638s 6s/step - loss: 6.6376 - accuracy: 0.0335\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 6.5023 - accuracy: 0.0419\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 6.4125 - accuracy: 0.0442\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 6.3296 - accuracy: 0.0484\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 6.2556 - accuracy: 0.0542\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 642s 6s/step - loss: 6.1954 - accuracy: 0.0585\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 6.1397 - accuracy: 0.0621\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 6.0847 - accuracy: 0.0661\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 644s 6s/step - loss: 6.0494 - accuracy: 0.0687\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 651s 7s/step - loss: 6.0625 - accuracy: 0.0686\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 650s 7s/step - loss: 5.9609 - accuracy: 0.0786\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 644s 6s/step - loss: 5.8546 - accuracy: 0.0887\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 5.7830 - accuracy: 0.0933\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 651s 7s/step - loss: 5.7299 - accuracy: 0.0942\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 5.6671 - accuracy: 0.0962\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 5.6003 - accuracy: 0.0988\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 5.5285 - accuracy: 0.1015\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 644s 6s/step - loss: 5.4586 - accuracy: 0.1033\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 5.3962 - accuracy: 0.1059\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 5.3286 - accuracy: 0.1077\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 641s 6s/step - loss: 5.2597 - accuracy: 0.1091\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 5.2004 - accuracy: 0.1119\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 5.1425 - accuracy: 0.1138\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 642s 6s/step - loss: 5.0828 - accuracy: 0.1166\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 5.0175 - accuracy: 0.1202\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 4.9517 - accuracy: 0.1246\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 4.9124 - accuracy: 0.1272\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 4.9056 - accuracy: 0.1296\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 651s 7s/step - loss: 4.8360 - accuracy: 0.1356\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 4.7777 - accuracy: 0.1387\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 650s 6s/step - loss: 4.6918 - accuracy: 0.1449\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 4.6164 - accuracy: 0.1521\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 4.5486 - accuracy: 0.1579\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 644s 6s/step - loss: 4.4936 - accuracy: 0.1632\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 4.4375 - accuracy: 0.1701\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 651s 7s/step - loss: 4.3714 - accuracy: 0.1763\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 644s 6s/step - loss: 4.3178 - accuracy: 0.1826\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 4.2743 - accuracy: 0.1877\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 4.2675 - accuracy: 0.1885\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 638s 6s/step - loss: 4.2016 - accuracy: 0.1958\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 658s 7s/step - loss: 4.1472 - accuracy: 0.2028\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 4.0935 - accuracy: 0.2090\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 639s 6s/step - loss: 4.0469 - accuracy: 0.2147\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 3.9966 - accuracy: 0.2206\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 3.9526 - accuracy: 0.2264\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 641s 6s/step - loss: 3.9104 - accuracy: 0.2318\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 653s 7s/step - loss: 3.8677 - accuracy: 0.2368\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 3.8288 - accuracy: 0.2419\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 3.7914 - accuracy: 0.2465\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 3.7515 - accuracy: 0.2521\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 3.7150 - accuracy: 0.2570\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 663s 7s/step - loss: 3.6797 - accuracy: 0.2614\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 3.6427 - accuracy: 0.2665\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 3.6108 - accuracy: 0.2711\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 3.5744 - accuracy: 0.2753\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 3.5430 - accuracy: 0.2799\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 3.5128 - accuracy: 0.2836\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 3.4831 - accuracy: 0.2880\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 3.4540 - accuracy: 0.2927\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 3.4222 - accuracy: 0.2967\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 3.3950 - accuracy: 0.3014\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 641s 6s/step - loss: 3.3686 - accuracy: 0.3042\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 3.3372 - accuracy: 0.3085\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 3.3097 - accuracy: 0.3130\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 642s 6s/step - loss: 3.2849 - accuracy: 0.3169\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 3.2570 - accuracy: 0.3210\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 3.2307 - accuracy: 0.3253\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 642s 6s/step - loss: 3.2062 - accuracy: 0.3289\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 644s 6s/step - loss: 3.1806 - accuracy: 0.3325\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 3.1578 - accuracy: 0.3358\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 3.1322 - accuracy: 0.3397\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 3.1086 - accuracy: 0.3437\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 3.0892 - accuracy: 0.3461\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 3.0618 - accuracy: 0.3509\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 3.0392 - accuracy: 0.3553\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 646s 6s/step - loss: 3.0171 - accuracy: 0.3573\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 2.9948 - accuracy: 0.3614\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 2.9726 - accuracy: 0.3658\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 2.9509 - accuracy: 0.3680\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 644s 6s/step - loss: 2.9317 - accuracy: 0.3724\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 2.9073 - accuracy: 0.3757\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 2.8893 - accuracy: 0.3787\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 2.8686 - accuracy: 0.3817\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 2.8469 - accuracy: 0.3855\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 2.8266 - accuracy: 0.3898\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 2.8086 - accuracy: 0.3921\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 2.7870 - accuracy: 0.3958\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 649s 6s/step - loss: 2.7663 - accuracy: 0.3994\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 645s 6s/step - loss: 2.7474 - accuracy: 0.4027\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 642s 6s/step - loss: 2.7306 - accuracy: 0.4049\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 650s 7s/step - loss: 2.7069 - accuracy: 0.4088\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 2.6893 - accuracy: 0.4118\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 642s 6s/step - loss: 2.6714 - accuracy: 0.4154\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 2.6538 - accuracy: 0.4173\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 643s 6s/step - loss: 2.6324 - accuracy: 0.4221\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 639s 6s/step - loss: 2.6158 - accuracy: 0.4254\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 2.5995 - accuracy: 0.4280\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 654s 7s/step - loss: 2.5791 - accuracy: 0.4311\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 640s 6s/step - loss: 2.5562 - accuracy: 0.4352\n"
     ]
    }
   ],
   "source": [
    "rnn_fit = model_rnn.fit(x_train, y_train, batch_size = 2000, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "789d8e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.save('text_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c5bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
